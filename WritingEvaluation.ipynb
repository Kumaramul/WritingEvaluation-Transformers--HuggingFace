{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "488b50a4-c2d9-4e65-a790-3efcc91fe0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "# GPU setup\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Configs\n",
    "VERSION = 26\n",
    "MODEL_NAME = 'google/bigbird-roberta-base'\n",
    "DATA_DIR = './data'\n",
    "MODEL_DIR = f'{DATA_DIR}/bigbird'\n",
    "\n",
    "CONFIG = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'max_length': 1024,\n",
    "    'train_batch_size': 4,\n",
    "    'valid_batch_size': 4,\n",
    "    'epochs': 5,\n",
    "    'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
    "    'max_grad_norm': 10,\n",
    "    'device': DEVICE,\n",
    "}\n",
    "\n",
    "COMPUTE_VAL_SCORE = len(os.listdir(f'{DATA_DIR}/test')) <= 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c1f56c3-131f-4c31-9682-dfdc1b60028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': 'google/bigbird-roberta-base',  # or your model path\n",
    "    'max_length': 1024,\n",
    "    'train_batch_size': 4,\n",
    "    'valid_batch_size': 4,\n",
    "    'epochs': 5,\n",
    "    'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
    "    'max_grad_norm': 10,\n",
    "    'device': 'cuda' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26a64ca0-e716-438f-a793-cf3cc4f44849",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "    # Load and save tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "    tokenizer.save_pretrained(MODEL_DIR)\n",
    "\n",
    "    # Load and save config with custom label count\n",
    "    config_model = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "    config_model.num_labels = 15\n",
    "    config_model.save_pretrained(MODEL_DIR)\n",
    "\n",
    "    # Load and save model\n",
    "    model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config_model)\n",
    "    model.save_pretrained(MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdc4edd3-73f1-4eec-b13c-d00813019aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "def read_texts(folder, limit=100):\n",
    "    filenames = os.listdir(folder)[:limit]\n",
    "    texts = [open(os.path.join(folder, f)).read() for f in filenames]\n",
    "    ids = [f.replace('.txt', '') for f in filenames]\n",
    "    return pd.DataFrame({'id': ids, 'text': texts})\n",
    "\n",
    "train_text_df = read_texts(f'{DATA_DIR}/train')\n",
    "test_text_df = read_texts(f'{DATA_DIR}/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19da8689-05fb-44cb-8a3a-898a6fa35e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "NER_PATH = f'{MODEL_DIR}/train_NER.csv'\n",
    "\n",
    "if os.path.exists(NER_PATH):\n",
    "    train_text_df = pd.read_csv(NER_PATH)\n",
    "    train_text_df['entities'] = train_text_df['entities'].apply(literal_eval)\n",
    "else:\n",
    "    all_entities = []\n",
    "    for _, row in tqdm(train_text_df.iterrows(), total=len(train_text_df)):\n",
    "        tokens = row['text'].split()\n",
    "        labels = ['O'] * len(tokens)\n",
    "        for _, ann in train_df[train_df['id'] == row['id']].iterrows():\n",
    "            idxs = list(map(int, ann['predictionstring'].split()))\n",
    "            labels[idxs[0]] = f'B-{ann[\"discourse_type\"]}'\n",
    "            for idx in idxs[1:]:\n",
    "                labels[idx] = f'I-{ann[\"discourse_type\"]}'\n",
    "        all_entities.append(labels)\n",
    "    train_text_df['entities'] = all_entities\n",
    "    train_text_df.to_csv(NER_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7193dce5-ff6e-4e1e-8978-54aa9d9b9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', \n",
    "                 'B-Counterclaim', 'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', \n",
    "                 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
    "\n",
    "ids_to_labels = {i: label for i, label in enumerate(output_labels)}\n",
    "output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', \n",
    "                 'B-Counterclaim', 'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', \n",
    "                 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
    "\n",
    "ids_to_labels = {i: label for i, label in enumerate(output_labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55767305-2e00-42c7-a016-d6df31df3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim',\n",
    "          'B-Counterclaim', 'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal',\n",
    "          'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(LABELS)}\n",
    "id2label = {i: label for i, label in enumerate(LABELS)}\n",
    "LABEL_ALL_SUBTOKENS = True\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, return_wids=False):\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.return_wids = return_wids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, 'text'].split()\n",
    "        labels = self.data.loc[idx, 'entities'] if not self.return_wids else None\n",
    "\n",
    "        encoding = self.tokenizer(text,\n",
    "                                  is_split_into_words=True,\n",
    "                                  padding='max_length',\n",
    "                                  truncation=True,\n",
    "                                  max_length=self.max_len)\n",
    "        \n",
    "        word_ids = encoding.word_ids()\n",
    "        if not self.return_wids:\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label2id[labels[word_idx]])\n",
    "                else:\n",
    "                    label_ids.append(label2id[labels[word_idx]] if LABEL_ALL_SUBTOKENS else -100)\n",
    "                previous_word_idx = word_idx\n",
    "            encoding['labels'] = label_ids\n",
    "\n",
    "        item = {key: torch.tensor(val) for key, val in encoding.items()}\n",
    "        if self.return_wids:\n",
    "            item['wids'] = torch.tensor([w if w is not None else -1 for w in word_ids])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c39fe1f-8f00-4aff-ad09-1682e92c3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "all_ids = train_df['id'].unique()\n",
    "train_ids = np.random.choice(all_ids, int(0.9 * len(all_ids)), replace=False)\n",
    "valid_ids = np.setdiff1d(all_ids, train_ids)\n",
    "\n",
    "train_data = train_text_df[train_text_df['id'].isin(train_ids)].reset_index(drop=True)\n",
    "valid_data = train_text_df[train_text_df['id'].isin(valid_ids)].reset_index(drop=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "train_dataset = NERDataset(train_data, tokenizer, CONFIG['max_length'], return_wids=False)\n",
    "valid_dataset = NERDataset(valid_data, tokenizer, CONFIG['max_length'], return_wids=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d6c4a5f-5ea1-4372-b680-df88f6c1b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_acc, steps = 0, 0, 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        ids = batch['input_ids'].to(DEVICE)\n",
    "        mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict=False)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['max_grad_norm'])\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        steps += 1\n",
    "\n",
    "        # Accuracy calculation\n",
    "        active = labels.view(-1) != -100\n",
    "        preds = torch.argmax(logits.view(-1, model.num_labels), axis=1)\n",
    "        acc = accuracy_score(labels.view(-1)[active].cpu(), preds[active].cpu())\n",
    "        total_acc += acc\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss/steps:.4f} | Accuracy: {total_acc/steps:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "487bc079-534b-4da5-8e03-eaf8b42a3658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from checkpoint.\n"
     ]
    }
   ],
   "source": [
    "config_model = AutoConfig.from_pretrained(f'{MODEL_DIR}/config.json')\n",
    "model = AutoModelForTokenClassification.from_pretrained(f'{MODEL_DIR}/pytorch_model.bin', config=config_model)\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['learning_rates'][0])\n",
    "\n",
    "model_path = f'{MODEL_DIR}/bigbird_v{VERSION}.pt'\n",
    "if not os.path.exists(model_path):\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = CONFIG['learning_rates'][epoch]\n",
    "        train_one_epoch(model, optimizer, epoch)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(\"Model loaded from checkpoint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6667b3f5-a007-42d4-8778-0dd1a96514a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, get_wids):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.get_wids = get_wids\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        text = self.data.text[index]        \n",
    "        word_labels = self.data.entities[index] if not self.get_wids else None\n",
    "\n",
    "        # TOKENIZE TEXT\n",
    "        encoding = self.tokenizer(text.split(),\n",
    "                             is_split_into_words=True,\n",
    "                             padding='max_length', \n",
    "                             truncation=True, \n",
    "                             max_length=self.max_len)\n",
    "        word_ids = encoding.word_ids()  \n",
    "\n",
    "        # CREATE TARGETS\n",
    "        if not self.get_wids:\n",
    "            previous_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:                            \n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:              \n",
    "                    label_ids.append(labels_to_ids[word_labels[word_idx]])\n",
    "                else:\n",
    "                    if LABEL_ALL_SUBTOKENS:\n",
    "                        label_ids.append(labels_to_ids[word_labels[word_idx]])\n",
    "                    else:\n",
    "                        label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "            encoding['labels'] = label_ids\n",
    "\n",
    "        # CONVERT TO TORCH TENSORS\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        if self.get_wids: \n",
    "            word_ids2 = [w if w is not None else -1 for w in word_ids]\n",
    "            item['wids'] = torch.as_tensor(word_ids2)\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81b7eca9-9648-4ee5-aa34-f0006cc4320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names, test_contents = [], []\n",
    "for f in list(os.listdir('./data/test')[:1000]):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    test_contents.append(open('./data/test/' + f, 'r').read())\n",
    "test_texts = pd.DataFrame({'id': test_names, 'text': test_contents})\n",
    "\n",
    "test_texts_set = dataset(test_texts, tokenizer, config['max_length'], get_wids=True)\n",
    "\n",
    "test_params = {\n",
    "    'batch_size': config['valid_batch_size'],\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "test_texts_loader = DataLoader(test_texts_set, **test_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5dcf018-af5a-4dcf-a422-1530784bb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(batch):\n",
    "    ids = batch[\"input_ids\"].to(config['device'])\n",
    "    mask = batch['attention_mask'].to(config['device'])\n",
    "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
    "    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() \n",
    "\n",
    "    predictions = []\n",
    "    for k, text_preds in enumerate(all_preds):\n",
    "        token_preds = [ids_to_labels[i] for i in text_preds]\n",
    "        prediction = []\n",
    "        word_ids = batch['wids'][k].numpy()\n",
    "        previous_word_idx = -1\n",
    "        for idx, word_idx in enumerate(word_ids):                            \n",
    "            if word_idx == -1:\n",
    "                pass\n",
    "            elif word_idx != previous_word_idx:              \n",
    "                prediction.append(token_preds[idx])\n",
    "                previous_word_idx = word_idx\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def get_predictions(df, loader):\n",
    "    model.eval()\n",
    "    y_pred2 = []\n",
    "\n",
    "    for batch in loader:\n",
    "        labels = inference(batch)\n",
    "        y_pred2.extend(labels)\n",
    "\n",
    "    final_preds2 = []\n",
    "    for i in range(len(df)):\n",
    "        idx = df.id.values[i]\n",
    "        pred = y_pred2[i]\n",
    "        preds = []\n",
    "        j = 0\n",
    "        while j < len(pred):\n",
    "            cls = pred[j]\n",
    "            if cls == 'O': \n",
    "                j += 1\n",
    "                continue\n",
    "            else: \n",
    "                cls = cls.replace('B', 'I')  # unify B- and I-\n",
    "            end = j + 1\n",
    "            while end < len(pred) and pred[end] == cls:\n",
    "                end += 1\n",
    "            if cls != 'O' and cls != '' and end - j > 7:\n",
    "                final_preds2.append((idx, cls.replace('I-', ''), ' '.join(map(str, range(j, end)))))\n",
    "            j = end\n",
    "\n",
    "    oof = pd.DataFrame(final_preds2)\n",
    "    oof.columns = ['id','class','predictionstring']\n",
    "    return oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab2434fe-3f13-4802-8b9a-a8f7ad77a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Practice Code\\code_env\\lib\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:977: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)\n"
     ]
    }
   ],
   "source": [
    "sub = get_predictions(test_texts, test_texts_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8505c082-c2c5-4a16-a200-e7218c141630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "To start this off it <span style=\"background-color:#FF6347; padding:2px; border-radius:3px;\">would be</span> a <span style=\"background-color:#98FB98; padding:2px; border-radius:3px;\">great idea</span> to study venus because it's some much different then earth. When looking at it from earth soemthimes it called Evening stars. Which is one of the brightest points of light in the night sky. Venus is alot different but at the same time alot alike. Venus is like earths twin its closest planet to earth in desity and size. Sometimes we arent as close to venus as we can be to mar. Mars, Earth, and Venus go around the sun at differsnt speed even though they are close to one an another. To conclude these two planets are very close but canbe very different. Earth has two planet that arent alike and different then it. Mars and venus, but these three can be really similar but very different in many ways. We have life here on Earth but mars and venus do not that we know of. "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Define colors for each class (you can customize)\n",
    "HIGHLIGHT_COLORS = {\n",
    "    'Lead': '#FFD700',            # gold\n",
    "    'Position': '#7FFFD4',        # aquamarine\n",
    "    'Claim': '#FF6347',           # tomato\n",
    "    'Counterclaim': '#FFB6C1',   # lightpink\n",
    "    'Rebuttal': '#87CEFA',        # lightskyblue\n",
    "    'Evidence': '#98FB98',        # palegreen\n",
    "    'Concluding Statement': '#FFA07A',  # lightsalmon\n",
    "    'O': '#FFFFFF'                # no highlight (white)\n",
    "}\n",
    "\n",
    "def highlight_text(text, predictions):\n",
    "    \"\"\"\n",
    "    text: str, the full original text\n",
    "    predictions: list of tuples like (class, start_idx, end_idx), \n",
    "                 where start_idx and end_idx are word indices of the predicted span\n",
    "    \n",
    "    Returns HTML with highlighted predicted spans.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    html_output = \"\"\n",
    "\n",
    "    current_pos = 0\n",
    "    for cls, start, end in sorted(predictions, key=lambda x: x[1]):\n",
    "        # Add unhighlighted words before this span\n",
    "        while current_pos < start:\n",
    "            html_output += words[current_pos] + \" \"\n",
    "            current_pos += 1\n",
    "        \n",
    "        # Highlight this span\n",
    "        color = HIGHLIGHT_COLORS.get(cls, \"#FFFF00\")  # default yellow\n",
    "        span_text = \" \".join(words[start:end+1])\n",
    "        html_output += f'<span style=\"background-color:{color}; padding:2px; border-radius:3px;\">{span_text}</span> '\n",
    "        current_pos = end + 1\n",
    "    \n",
    "    # Add remaining words after last span\n",
    "    while current_pos < len(words):\n",
    "        html_output += words[current_pos] + \" \"\n",
    "        current_pos += 1\n",
    "    \n",
    "    return html_output\n",
    "\n",
    "# Usage example:\n",
    "sample_row = valid_data.loc[0]\n",
    "sample_id = sample_row['id']\n",
    "sample_text = sample_row['text']\n",
    "sample_predictions = [\n",
    "    (\"Claim\", 5, 6),         # highlight words 5 and 6 as Claim\n",
    "    (\"Evidence\", 8, 9)       # highlight words 8 and 9 as Evidence\n",
    "]\n",
    "\n",
    "display(HTML(highlight_text(sample_text, sample_predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "149696d6-ccad-4875-aea4-d8a43e94d575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><b>Predicted Entities for ID: 527EB3C89F2F</b><br><p style='line-height:1.6;font-size:15px'>To start this off it would be a great idea to study venus because it's some much different then earth. When looking at it from earth soemthimes it called Evening stars. Which is one of the brightest points of light in the night sky. Venus is alot different but at the same time alot alike. Venus is like earths twin its closest planet to earth in desity and size. Sometimes we arent as close to venus as we can be to mar. Mars, Earth, and Venus go around the sun at differsnt speed even though they are close to one an another. To conclude these two planets are very close but canbe very different. Earth has two planet that arent alike and different then it. Mars and venus, but these three can be really similar but very different in many ways. We have life here on Earth but mars and venus do not that we know of.</p></div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_row = valid_data.loc[0]\n",
    "sample_id = sample_row['id']\n",
    "sample_text = sample_row['text']\n",
    "\n",
    "sample_preds = sub[sub['id'] == sample_id][['class', 'predictionstring']].values.tolist()\n",
    "\n",
    "\n",
    "highlight_predictions(sample_text, sample_preds, title=f\"Predicted Entities for ID: {sample_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974c654-21f4-4b2b-99f7-e5281866b8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d09e5951-56f9-4ec0-b221-6a592679803c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Workspace\\Practice Code\\code_env\\lib\\site-packages\\transformers\\models\\big_bird\\modeling_big_bird.py:977: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#7FFFD4; padding:2px; border-radius:3px;\">To start this off it would be a great idea to study venus because it's</span> <span style=\"background-color:#FF6347; padding:2px; border-radius:3px;\">some much different then earth.</span> <span style=\"background-color:#98FB98; padding:2px; border-radius:3px;\">When looking at it from earth soemthimes it called Evening stars. Which is one of the brightest points of light in the night sky. Venus is alot different but at the same time alot alike. Venus is like earths twin its closest planet to earth in desity and size. Sometimes we arent as close to venus as we can be to mar. Mars, Earth, and Venus go around the sun at differsnt speed even though they are close to one an another.</span> <span style=\"background-color:#FFA07A; padding:2px; border-radius:3px;\">To conclude these two planets are very close but canbe very different. Earth has two planet that arent alike and different then it. Mars and venus, but these three can be really similar but very different in many ways. We have life here on Earth but mars and venus do not that we know of.</span> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sample_row = valid_data.loc[0]\n",
    "sample_id = sample_row['id']\n",
    "sample_text = sample_row['text']\n",
    "\n",
    "\n",
    "sample_df = pd.DataFrame({'text': [sample_text], 'entities': [None]})\n",
    "sample_dataset = dataset(sample_df, tokenizer, config['max_length'], get_wids=True)\n",
    "sample_loader = DataLoader(sample_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in sample_loader:\n",
    "        preds = inference(batch)\n",
    "\n",
    "def preds_to_spans(preds):\n",
    "    spans = []\n",
    "    j = 0\n",
    "    while j < len(preds):\n",
    "        cls = preds[j]\n",
    "        if cls == 'O':\n",
    "            j += 1\n",
    "        else:\n",
    "            cls_type = cls.replace('B-', '').replace('I-', '')\n",
    "            end = j + 1\n",
    "            while end < len(preds) and preds[end] == f\"I-{cls_type}\":\n",
    "                end += 1\n",
    "            spans.append((cls_type, j, end - 1))\n",
    "            j = end\n",
    "    return spans\n",
    "\n",
    "sample_spans = preds_to_spans(preds[0])\n",
    "\n",
    "# Step 5: visualize\n",
    "display(HTML(highlight_text(sample_text, sample_spans)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfe4c3-5f73-453b-a99f-25996249fbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5953d69-1f8f-40ba-a5f2-d4980d3c149e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cacf39-4d91-4dc2-9e42-56e7b842f178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
